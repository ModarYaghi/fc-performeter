{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No password for tt_pt_FM_v04.11.xlsx\n"
     ]
    }
   ],
   "source": [
    "from src.all_in_one import *\n",
    "\n",
    "# Set the pandas option\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528454c9601986a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = path_manager.processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5603c8e8edbaa9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all rid across all datasets\n",
    "rid = pd.DataFrame()  # An empty dataframe\n",
    "if os.path.exists(processed_data_path) and os.path.isdir(processed_data_path):\n",
    "    for file_name in os.listdir(processed_data_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(processed_data_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_rid = df[\"rid\"]\n",
    "            rid = pd.concat([rid, df_rid])\n",
    "rid = rid.drop_duplicates(keep=\"first\")\n",
    "rid = rid.sort_values(by=\"rid\", ascending=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e576ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rid.to_clipboard(index=False)\n",
    "pd.read_excel(\"sub_id.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d7d1d84b927cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sub_id.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# the script in this cell is for consolidating firstnames, lastnames, sex, and age, for some of the rid that don't have these values from the screening.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# So, i needed to collect them from other services.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sub_id \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msub_id.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# It seems that I forget how I created \"sub_id.xlsx\"!\u001b[39;00m\n\u001b[0;32m      7\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m sub_id\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Initialize merged_df to avoid referencing before assignment\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(processed_data_path):\n",
      "File \u001b[1;32mc:\\Users\\myagh\\fc-performeter\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\myagh\\fc-performeter\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\myagh\\fc-performeter\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\myagh\\fc-performeter\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sub_id.xlsx'"
     ]
    }
   ],
   "source": [
    "# the script in this cell is for consolidating firstnames, lastnames, sex, and age, for some of the rid that don't have these values from the screening.\n",
    "# So, i needed to collect them from other services.\n",
    "\n",
    "sub_id = pd.read_excel(\n",
    "    \"sub_id.xlsx\"\n",
    ")  # It seems that I forget how I created \"sub_id.xlsx\"!\n",
    "merged_df = sub_id.copy()  # Initialize merged_df to avoid referencing before assignment\n",
    "\n",
    "for filename in os.listdir(processed_data_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(processed_data_path, filename)\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Check if the needed columns exist in this dataset\n",
    "        columns_needed = [\"rid\", \"firstname\", \"lastname\", \"sex\", \"age\"]\n",
    "        common_columns = [col for col in columns_needed if col in data.columns]\n",
    "\n",
    "        # Ensure 'rid' is present before merging\n",
    "        if \"rid\" in common_columns:\n",
    "            merged_df = merged_df.merge(\n",
    "                data[common_columns],\n",
    "                on=\"rid\",\n",
    "                how=\"left\",\n",
    "                suffixes=(\"\", f\"_from_{filename}\"),\n",
    "            )\n",
    "\n",
    "# Optional: Consolidate columns, for example, firstname from different files\n",
    "for col in [\"firstname\", \"lastname\", \"sex\", \"age\"]:\n",
    "    columns_to_combine = [c for c in merged_df.columns if c.startswith(col)]\n",
    "    merged_df[col] = (\n",
    "        merged_df[columns_to_combine].bfill(axis=1).iloc[:, 0].infer_objects()\n",
    "    )\n",
    "    merged_df.drop(\n",
    "        columns=columns_to_combine[1:], inplace=True\n",
    "    )  # Drop extra columns after combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591150837c0b40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.drop_duplicates(subset=\"rid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbadf77b48fc4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540564c72e95584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screening Dataset\n",
    "# scr_file = path_manager.get_data_file(Category.PS, PSFile.SCR)\n",
    "# scr_dataset = Dataset(config_file, scr_file.sheet)\n",
    "# scr = get_df(scr_file.path, scr_file.sheet, config_file).sort_values(by='sc_s1', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ac39a953bf866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Screening basic session separated form pei_pre_as and re-screening\n",
    "# columns_to_drop = ['scspi','nat', 'need_mhpss', 'need_trw', 'need_out_ref', 'need_tmh', 'need_pei', 'note','pei_pre_as', 'sc_re']\n",
    "# columns_to_drop = ['note','pei_pre_as', 'sc_re']\n",
    "# scr_0 = scr.drop(columns=columns_to_drop).dropna(subset=['sc_s1']).sort_values(by='sc_s1')  # Screening basic session. Records = 705\n",
    "# scr_0 = scr_0.drop_duplicates(subset=['rid'], keep='first')  # There are 6 rid duplicated.\n",
    "# re_scr = scr[['rid','sc_re']].dropna()  # Screening re. Records = 41\n",
    "# pei_pre_as = scr[['rid','pei_pre_as']].dropna()  # PEI Assessment. Records = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c35d7cf8581f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pei_pre_as\n",
    "# re_scr\n",
    "# scr_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cab7b831e0448",
   "metadata": {},
   "source": [
    "Note: You need to rearrange the two columns to be in their positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1cf2ebf589285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated_dataset_scr = pd.merge(rid, scr_0, on='rid', how='left')\n",
    "# consolidated_dataset_scr = pd.merge(consolidated_dataset_scr, re_scr, on='rid', how='left')\n",
    "# consolidated_dataset_scr = pd.merge(consolidated_dataset_scr, pei_pre_as, on='rid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf076cdd9bbe88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidated_dataset_scr.to_csv('consolidated_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19b018a736cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('consolidated_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
